{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from oct_dataset import OCTDataset\n",
    "from models import UnetNoPretraining, MedSAM\n",
    "from lossfunctions import DiceLoss, DiceBCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from filelock import FileLock\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from typing import Dict\n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.train import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray import tune, air\n",
    "from ray.air import session\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import neptune\n",
    "import segmentation_models_pytorch as smp\n",
    "from segment_anything import sam_model_registry\n",
    "os.environ[\"TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S\"] = \"0\"\n",
    "\n",
    "def train_model_cv(config):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    if config[\"model\"] == \"Unet\":\n",
    "        # Initialize model with the hyperparameters from the config\n",
    "        net = smp.Unet(\n",
    "            encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "            encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "            in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "            classes=1,                      # model output channels (number of classes in your dataset)\n",
    "            activation=\"sigmoid\",           # output activation (sigmoid for binary segmentation)\n",
    "        )\n",
    "        if config[\"freeze_encoder\"]:\n",
    "            for param in net.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    elif config[\"model\"] == \"DeepLabV3+\":\n",
    "        net = smp.DeepLabV3Plus(\n",
    "            encoder_name=\"resnet34\",\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=3,\n",
    "            classes=1,\n",
    "            activation=\"sigmoid\",\n",
    "        )\n",
    "        if config[\"freeze_encoder\"]:\n",
    "            for param in net.encoder.parameters():\n",
    "                param.requires_grad = False \n",
    "    \n",
    "    elif config[\"model\"] == \"MedSam\":\n",
    "        MedSAM_CKPT_PATH = r\"D:\\OneDrive - Aarhus Universitet\\9. Semester\\Deep Learning\\medsam\\medsam_vit_b.pth\"\n",
    "        sam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)\n",
    "        net = MedSAM(\n",
    "                image_encoder=sam_model.image_encoder,\n",
    "                mask_decoder=sam_model.mask_decoder,\n",
    "                prompt_encoder=sam_model.prompt_encoder,\n",
    "            ).to(device)\n",
    "        \n",
    "        if config[\"freeze_encoder\"]:\n",
    "            # Freeze the image encoder\n",
    "            for param in net.image_encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    elif config[\"model\"] == \"AttentionUnet\":\n",
    "        # Initialize model \n",
    "        print(\"Initializing Attention U-Net model\")\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "    # Select optimizer based on the configuration\n",
    "    if config[\"optimizer\"] == \"AdamW\":\n",
    "        optimizer = optim.AdamW(net.parameters(), lr=config[\"lr\"])\n",
    "    elif config[\"optimizer\"] == \"SGD\":\n",
    "        optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "    elif config[\"optimizer\"] == \"RMSprop\":\n",
    "        optimizer = optim.RMSprop(net.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    # Select loss function based on the configuration\n",
    "    if config[\"loss_function\"] == \"DiceLoss\":\n",
    "        criterion = DiceLoss()\n",
    "    elif config[\"loss_function\"] == \"DiceBCELoss\":\n",
    "        criterion = DiceBCELoss()\n",
    "    elif config[\"loss_function\"] == \"BCELoss\":\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256), interpolation=Image.NEAREST),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Load existing checkpoint through `get_checkpoint()` API.\n",
    "    if train.get_checkpoint():\n",
    "        loaded_checkpoint = train.get_checkpoint()\n",
    "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "            model_state, optimizer_state = torch.load(\n",
    "                os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\")\n",
    "            )\n",
    "            net.load_state_dict(model_state)\n",
    "            optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    root_dir = config[\"root_dir\"]\n",
    "    folds= config[\"folds\"]\n",
    "    \n",
    "    with open(os.path.join(root_dir, \"metadata.csv\"), \"r\") as f:\n",
    "        metadata_df = pd.read_csv(f)\n",
    "        skf = StratifiedKFold(n_splits=folds)\n",
    "        splits = list(skf.split(metadata_df, metadata_df[\"unique_id\"]))\n",
    "\n",
    "    train_and_validate(root_dir, config, splits, folds, transform, optimizer, criterion, net, device)\n",
    "\n",
    "\n",
    "def train_and_validate(root_dir, config, splits, folds, transform, optimizer, criterion, net, device, medsam=False):\n",
    "    for fold in range(folds):\n",
    "        # Train and validate the model\n",
    "        print(f\"Training on fold {fold+1} out of {folds}\")\n",
    "        \n",
    "        # Initialize Neptune run\n",
    "        run = neptune.init_run(\n",
    "            project=\"OCTAA/OCTSegmenter\",\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI2MGU2NGNjMi0yNWE0LTRjNzgtOGNlNS1hZDdkMjJhYzYxMWUifQ==\",\n",
    "            name=\"training_and_validation\",\n",
    "            tags=\"terumo\",\n",
    "        )  # your credentials\n",
    "\n",
    "        run[\"sys/group_tags\"].add([\n",
    "            str(config[\"model\"]),\n",
    "            str(config[\"freeze_encoder\"]),\n",
    "            str(config[\"loss_function\"]), \n",
    "            str(config[\"optimizer\"]), \n",
    "            f\"Fold: {str(fold)}\"\n",
    "        ])  # Group tags\n",
    "\n",
    "        # Log configuration parameters\n",
    "        run[\"parameters\"] = config\n",
    "\n",
    "        train_indices, val_indices = splits[fold]\n",
    "\n",
    "        train_dataset = OCTDataset(root_dir, indices=train_indices, transform=transform)\n",
    "        val_dataset = OCTDataset(root_dir, indices=val_indices, transform=transform)\n",
    "\n",
    "        trainloader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "        valloader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "        best_val_loss = float(\"inf\")\n",
    "        epochs = config[\"epochs\"]\n",
    "        no_improvement_epochs = 0\n",
    "        patience = config[\"patience\"]\n",
    "        scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=10)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            net.train()\n",
    "            running_loss = 0.0\n",
    "            epoch_steps= 0\n",
    "\n",
    "            for i, data in enumerate(trainloader):\n",
    "                if config[\"model\"] == \"MedSam\":\n",
    "                    images, masks, _, _ = data\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                     # Get image dimensions\n",
    "                    batch_size, _, height, width = images.size()\n",
    "\n",
    "                    # Create bounding boxes that cover the whole image\n",
    "                    bboxes = torch.tensor([[0, 0, width, height]] * batch_size, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = net(images, bboxes)\n",
    "                    loss = criterion(outputs, masks)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                else:\n",
    "                    images, masks, _, _ = data\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = net(images)\n",
    "                    loss = criterion(outputs, masks)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "\n",
    "                epoch_steps += 1\n",
    "                if i % 10 == 9:  # print every 10 mini-batches\n",
    "                    print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                    loss.item()))\n",
    "\n",
    "\n",
    "            # Calculate training loss and accuracy for the epoch\n",
    "            train_loss = running_loss / len(trainloader.dataset)\n",
    "            run[\"train_loss\"].append(train_loss)  # Log training loss to neptune\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "            # Validation phase\n",
    "            net.eval()\n",
    "            val_loss = 0.0\n",
    "            dice_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():  # No need to calculate gradients during validation\n",
    "                for data in valloader:\n",
    "                    if config[\"model\"] == \"MedSam\":\n",
    "                        images, masks, _, _ = data\n",
    "                        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                        # Get image dimensions\n",
    "                        batch_size, _, height, width = images.size()\n",
    "\n",
    "                        # Create bounding boxes that cover the whole image\n",
    "                        bboxes = torch.tensor([[0, 0, width, height]] * batch_size, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "                        outputs = net(images, bboxes)\n",
    "                        loss = criterion(outputs, masks)\n",
    "                        val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                    else:\n",
    "                        images, masks, _, _ = data\n",
    "                        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                        outputs = net(images)\n",
    "                        loss = criterion(outputs, masks)\n",
    "                        val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                    # Calculate Dice loss\n",
    "                    dice = DiceLoss()\n",
    "                    loss = dice(outputs, masks)\n",
    "                    dice_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Calculate validation loss and accuracy\n",
    "            val_loss = val_loss / len(valloader.dataset)\n",
    "            avg_dice_loss = dice_loss / len(valloader.dataset)\n",
    "            scheduler.step(val_loss) # Adjust learning rate based on validation loss\n",
    "            run[\"val_loss\"].append(val_loss)  # Log validation loss\n",
    "            run[\"dice_loss\"].append(avg_dice_loss)  # Log Dice loss\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "            with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "                path = os.path.join(temp_checkpoint_dir, \"checkpoint.pt\")\n",
    "                torch.save(\n",
    "                    (net.state_dict(), optimizer.state_dict()), path\n",
    "                )\n",
    "                checkpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "                train.report(\n",
    "                    {\"loss\": val_loss, \"accuracy\": 1 - avg_dice_loss, \"dice_loss\": avg_dice_loss, \"fold\": fold},\n",
    "                    checkpoint=checkpoint,\n",
    "                )\n",
    "\n",
    "            # Check if validation loss improves\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                no_improvement_epochs = 0\n",
    "                print(f\"Validation loss improved to {val_loss:.4f}. Saving checkpoint.\")\n",
    "                \n",
    "            else:\n",
    "                no_improvement_epochs += 1\n",
    "                print(f\"Validation loss did not improve. Best so far: {best_val_loss:.4f}\")\n",
    "            \n",
    "            if no_improvement_epochs >= patience:\n",
    "                print(f\"Stopping early. No improvement in {patience} epochs.\")\n",
    "                run[\"early_stopping\"] = True\n",
    "                break\n",
    "\n",
    "        run.stop()\n",
    "        print(\"Finished Training\")\n",
    "\n",
    "    \n",
    "def test_best_model(best_result):\n",
    "    \n",
    "    # Initialize Neptune run\n",
    "    run = neptune.init_run(\n",
    "        project=\"OCTAA/OCTSegmenter\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI2MGU2NGNjMi0yNWE0LTRjNzgtOGNlNS1hZDdkMjJhYzYxMWUifQ==\",\n",
    "        name=\"best_model_test\",\n",
    "        tags=\"gentuity\"  \n",
    "    )  # your credentials\n",
    "\n",
    "    # Log configuration parameters\n",
    "    run[\"parameters\"] = best_result.config\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    best_trained_model = UnetNoPretraining().to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "\n",
    "    model_state, optimizer_state = torch.load(checkpoint_path, weights_only=True)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((1024, 1024), interpolation=Image.NEAREST),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    root_dir = r\"D:\\OneDrive - Aarhus Universitet\\9. Semester\\Deep Learning\\data_gentuity\"\n",
    "\n",
    "    test_dataset = OCTDataset(root_dir, transform=transform, train=False, is_gentuity=True)\n",
    "    testloader = DataLoader(test_dataset, batch_size=best_result.config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    criterion = DiceLoss()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for data in testloader:\n",
    "            if best_result.config[\"model\"] == \"MedSam\":\n",
    "                images, masks, _, _ = data\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                # Get image dimensions\n",
    "                batch_size, _, height, width = images.size()\n",
    "\n",
    "                # Create bounding boxes that cover the whole image\n",
    "                bboxes = torch.tensor([[0, 0, width, height]] * batch_size, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "                outputs = best_trained_model(images, bboxes)\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                loss = criterion(predicted, masks)\n",
    "                total_loss += loss.item() * images.size(0)\n",
    "\n",
    "            else:\n",
    "                images, masks, _, _ = data\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                outputs = best_trained_model(images)\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                loss = criterion(predicted, masks)\n",
    "                total_loss += loss.item() * images.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    total_loss /= len(testloader.dataset)\n",
    "    accuracy = 1 - loss\n",
    "\n",
    "    run[\"test_loss\"] = total_loss\n",
    "    run.stop()\n",
    "    print(f\"Test Loss: {total_loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-11-28 15:32:02</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:08.54        </td></tr>\n",
       "<tr><td>Memory:      </td><td>15.5/15.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 2.0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th>freeze_encoder  </th><th>loss_function  </th><th style=\"text-align: right;\">         lr</th><th>model     </th><th>optimizer  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_cv_83309_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">8.71671e-05</td><td>Unet      </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">1.0338e-05 </td><td>Unet      </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">0.00727547 </td><td>Unet      </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">0.00917043 </td><td>Unet      </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.00447867 </td><td>Unet      </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.00234499 </td><td>Unet      </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">0.000171796</td><td>DeepLabV3+</td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">2.24845e-06</td><td>DeepLabV3+</td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">0.000201035</td><td>DeepLabV3+</td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">7.49124e-06</td><td>DeepLabV3+</td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">6.81177e-06</td><td>DeepLabV3+</td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">1.71609e-06</td><td>DeepLabV3+</td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">1.3781e-06 </td><td>MedSam    </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">0.00759188 </td><td>MedSam    </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">0.0014157  </td><td>MedSam    </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">0.000283102</td><td>MedSam    </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.00483261 </td><td>MedSam    </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">1.47028e-06</td><td>MedSam    </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">0.000256021</td><td>Unet      </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">4.38105e-05</td><td>Unet      </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00020</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">0.00143743 </td><td>Unet      </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00021</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">0.000130965</td><td>Unet      </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00022</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.000285462</td><td>Unet      </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00023</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">1.7578e-05 </td><td>Unet      </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00024</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">2.96369e-05</td><td>DeepLabV3+</td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00025</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">0.000101419</td><td>DeepLabV3+</td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00026</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">0.000775757</td><td>DeepLabV3+</td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00027</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">0.00140084 </td><td>DeepLabV3+</td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00028</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">1.47132e-06</td><td>DeepLabV3+</td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00029</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">1.89363e-06</td><td>DeepLabV3+</td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00030</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">5.94752e-05</td><td>MedSam    </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00031</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">1.1623e-06 </td><td>MedSam    </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00032</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">0.000688686</td><td>MedSam    </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00033</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">1.34082e-06</td><td>MedSam    </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00034</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">2.07559e-05</td><td>MedSam    </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00035</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.000857062</td><td>MedSam    </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00036</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">0.00829539 </td><td>Unet      </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00037</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">8.75636e-06</td><td>Unet      </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00038</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">5.07457e-05</td><td>Unet      </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00039</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">0.00959153 </td><td>Unet      </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00040</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">6.00787e-06</td><td>Unet      </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00041</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">2.10894e-06</td><td>Unet      </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00042</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">0.00592638 </td><td>DeepLabV3+</td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00043</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">1.45317e-05</td><td>DeepLabV3+</td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00044</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">0.00240403 </td><td>DeepLabV3+</td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00045</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">6.20643e-06</td><td>DeepLabV3+</td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00046</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">1.33839e-06</td><td>DeepLabV3+</td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00047</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.00708902 </td><td>DeepLabV3+</td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00048</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">3.74937e-05</td><td>MedSam    </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00049</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">7.16499e-05</td><td>MedSam    </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00050</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">0.00531569 </td><td>MedSam    </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00051</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">6.7975e-06 </td><td>MedSam    </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00052</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">3.01022e-06</td><td>MedSam    </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00053</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">2.264e-05  </td><td>MedSam    </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00054</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">2.63519e-06</td><td>Unet      </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00055</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">1.48208e-06</td><td>Unet      </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00056</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">0.000542987</td><td>Unet      </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00057</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">0.000334339</td><td>Unet      </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00058</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.00310932 </td><td>Unet      </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00059</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.000930834</td><td>Unet      </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00060</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">0.00870453 </td><td>DeepLabV3+</td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00061</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">5.75346e-05</td><td>DeepLabV3+</td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00062</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">0.000157083</td><td>DeepLabV3+</td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00063</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">0.00114947 </td><td>DeepLabV3+</td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00064</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.000471349</td><td>DeepLabV3+</td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00065</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.00568432 </td><td>DeepLabV3+</td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00066</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">4.87067e-06</td><td>MedSam    </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00067</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">1.74672e-05</td><td>MedSam    </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00068</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">5.62042e-06</td><td>MedSam    </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00069</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">2.91258e-06</td><td>MedSam    </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00070</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">7.91459e-06</td><td>MedSam    </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00071</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">4.17075e-05</td><td>MedSam    </td><td>AdamW      </td></tr>\n",
       "<tr><td>train_model_cv_83309_00072</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">0.000103298</td><td>Unet      </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00073</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">6.5385e-06 </td><td>Unet      </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00074</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">4.51398e-05</td><td>Unet      </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00075</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">0.000778544</td><td>Unet      </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00076</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">4.89019e-06</td><td>Unet      </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00077</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.00296445 </td><td>Unet      </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00078</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">4.42302e-05</td><td>DeepLabV3+</td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00079</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">0.0055909  </td><td>DeepLabV3+</td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00080</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">2.37007e-06</td><td>DeepLabV3+</td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00081</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">0.00238096 </td><td>DeepLabV3+</td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00082</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">2.78388e-06</td><td>DeepLabV3+</td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00083</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">1.26974e-05</td><td>DeepLabV3+</td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00084</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">9.14015e-05</td><td>MedSam    </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00085</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">3.82333e-05</td><td>MedSam    </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00086</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">4.32071e-05</td><td>MedSam    </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00087</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">0.00513196 </td><td>MedSam    </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00088</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.00019599 </td><td>MedSam    </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00089</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.00941238 </td><td>MedSam    </td><td>SGD        </td></tr>\n",
       "<tr><td>train_model_cv_83309_00090</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">7.35085e-06</td><td>Unet      </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00091</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">1.19155e-06</td><td>Unet      </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00092</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">1.21626e-05</td><td>Unet      </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00093</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">0.000744743</td><td>Unet      </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00094</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.00188644 </td><td>Unet      </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00095</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.000879742</td><td>Unet      </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00096</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">1.37155e-05</td><td>DeepLabV3+</td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00097</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">3.69735e-06</td><td>DeepLabV3+</td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00098</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">1.22816e-06</td><td>DeepLabV3+</td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00099</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">3.70441e-06</td><td>DeepLabV3+</td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00100</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.00287919 </td><td>DeepLabV3+</td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00101</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.00548648 </td><td>DeepLabV3+</td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00102</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceLoss       </td><td style=\"text-align: right;\">2.51533e-06</td><td>MedSam    </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00103</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceLoss       </td><td style=\"text-align: right;\">0.000967718</td><td>MedSam    </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00104</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>BCELoss        </td><td style=\"text-align: right;\">0.00112397 </td><td>MedSam    </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00105</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>BCELoss        </td><td style=\"text-align: right;\">0.00517962 </td><td>MedSam    </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00106</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>True            </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.000187623</td><td>MedSam    </td><td>RMSprop    </td></tr>\n",
       "<tr><td>train_model_cv_83309_00107</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td>False           </td><td>DiceBCELoss    </td><td style=\"text-align: right;\">0.000833085</td><td>MedSam    </td><td>RMSprop    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 15:32:01,948\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-11-28 15:32:02,046\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/johan/ray_results/train_model_cv_2024-11-28_15-31-40' in 0.0940s.\n"
     ]
    }
   ],
   "source": [
    "from ray.train import RunConfig, CheckpointConfig\n",
    "\n",
    "def plot_cv_indices(cv, X, y, ax, n_splits, lw=10, cmap_data=\"tab10\"):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1  # Mark the test samples\n",
    "        indices[tr] = 0  # Mark the train samples\n",
    "\n",
    "        # Visualize the results for the current split\n",
    "        # Train samples in light blue, validation samples in redder orange\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=np.where(indices == 0, '#add8e6', '#ff4500'),  # Set light blue and redder orange\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "        )\n",
    "\n",
    "    # Plot the unique_id at the end (instead of class labels)\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    # Add a legend for train and validation splits\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='#add8e6', lw=4, label='Train'),\n",
    "        Line2D([0], [0], color='#ff4500', lw=4, label='Validation'),\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + [\"unique_id\"]\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits + 1) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[n_splits + 1.2, -0.2],\n",
    "        xlim=[0, len(X)],\n",
    "    )\n",
    "    ax.set_title(f\"{type(cv).__name__} Cross-Validation\", fontsize=15)\n",
    "    return ax\n",
    "\n",
    "# Visualize splits\n",
    "def visualize_cv_splits(metadata_df, n_splits=9):\n",
    "    # Extract unique IDs and their corresponding target (unique_id)\n",
    "    unique_ids = metadata_df[\"unique_id\"].values\n",
    "\n",
    "    # Initialize StratifiedKFold with n_splits\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the cross-validation splits\n",
    "    plot_cv_indices(\n",
    "        skf, X=metadata_df, y=unique_ids, ax=ax, n_splits=n_splits\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Custom function to shorten trial directory names\n",
    "def trial_dirname_creator(trial):\n",
    "    # Shorten the trial name to only include key parameters\n",
    "    return f\"trial_{trial.trial_id}_lr={trial.config['lr']:.1e}_opt={trial.config['optimizer']}_bs={trial.config['batch_size']}_model={trial.config['model']}_freeze={trial.config['freeze_encoder']}_loss={trial.config['loss_function']}\"\n",
    "\n",
    "def main(num_samples, gpus_per_trial, epochs, smoke_test, folds):\n",
    "    if smoke_test:\n",
    "        root_dir = r\"D:\\OneDrive - Aarhus Universitet\\9. Semester\\Deep Learning\\data_terumo_smoke_test\"\n",
    "        with open(os.path.join(root_dir, \"metadata.csv\"), \"r\") as f:\n",
    "            metadata_df = pd.read_csv(f)\n",
    "            skf = StratifiedKFold(n_splits=folds)\n",
    "            visualize_cv_splits(metadata_df, n_splits=folds)\n",
    "\n",
    "    else:\n",
    "        print(\"Using full dataset\")\n",
    "    \n",
    "    config = {\n",
    "        \"root_dir\": root_dir,\n",
    "        \"lr\": tune.loguniform(1e-6, 1e-2),\n",
    "        \"epochs\": epochs,\n",
    "        \"smoke_test\": smoke_test,\n",
    "        \"batch_size\": tune.choice([4]),\n",
    "        \"optimizer\": tune.grid_search([\"AdamW\", \"SGD\", \"RMSprop\"]),\n",
    "        \"folds\": folds,\n",
    "        \"patience\": 20,\n",
    "        \"loss_function\": tune.grid_search([\"DiceLoss\", \"BCELoss\", \"DiceBCELoss\"]),\n",
    "        \"model\": tune.grid_search([\"AttentionUnet\", \"Unet\", \"DeepLabV3+\", \"MedSam\"]),\n",
    "        \"freeze_encoder\": tune.grid_search([True, False]),\n",
    "    }\n",
    "\n",
    "    # ASHA SCHEDULER, BUT WILL NOT BE USED\n",
    "    # scheduler = ASHAScheduler(\n",
    "    #     max_t=5,\n",
    "    #     grace_period=5,\n",
    "    #     reduction_factor=2\n",
    "    # )\n",
    "\n",
    "    # Define your checkpoint configuration\n",
    "    checkpoint_config = CheckpointConfig(\n",
    "        num_to_keep=1,  # Only keep the best checkpoint\n",
    "        checkpoint_score_attribute=\"loss\",  # The metric used to determine the best checkpoint\n",
    "        checkpoint_score_order=\"min\",  # Keep the checkpoint with the lowest loss\n",
    "    )\n",
    "\n",
    "    # Define the run config with the checkpoint config\n",
    "    run_config = RunConfig(checkpoint_config=checkpoint_config)\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(train_model_cv),\n",
    "            resources={\"cpu\": 2, \"gpu\": gpus_per_trial}\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"dice_loss\",\n",
    "            mode=\"min\",\n",
    "            num_samples=num_samples,\n",
    "            trial_dirname_creator=trial_dirname_creator,\n",
    "        ),\n",
    "        param_space=config,\n",
    "        run_config=run_config,\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    \n",
    "    best_result = results.get_best_result(\"dice_loss\", \"min\")\n",
    "\n",
    "    print(\"Best trial config: {}\".format(best_result.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_result.metrics[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_result.metrics[\"accuracy\"]))\n",
    "\n",
    "    test_best_model(best_result)\n",
    "\n",
    "main(num_samples=2, gpus_per_trial=1, epochs=2, smoke_test=True, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results from C:\\Users\\johan\\ray_results\\train_model_cv_2024-11-26_18-30-35...\n",
      "One of the trials failed!\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 112] Failed copying 'C:/Users/johan/ray_results/train_model_cv_2024-11-26_18-30-35/trial_2b60a_00035_lr=1.0e-04_opt=RMSprop_bs=4/checkpoint_000004/checkpoint.pt' to 'C:/Users/johan/AppData/Local/Temp/checkpoint_tmp_eb1ac5460b9145e2847271a019179487/checkpoint.pt'. Detail: [Windows error 112] Der er ikke tilstrækkelig plads på disken.\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Load the best checkpoint if it exists\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_result\u001b[38;5;241m.\u001b[39mcheckpoint:\n\u001b[1;32m---> 24\u001b[0m     checkpoint_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(best_result\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mto_directory(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo checkpoint found for the best result.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\johan\\anaconda3\\envs\\dl\\Lib\\site-packages\\ray\\train\\_checkpoint.py:216\u001b[0m, in \u001b[0;36mCheckpoint.to_directory\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# Timeout 0 means there will be only one attempt to acquire\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the file lock. If it cannot be acquired, throw a TimeoutError\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m TempFileLock(local_path, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m--> 216\u001b[0m         _download_from_fs_path(\n\u001b[0;32m    217\u001b[0m             fs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilesystem, fs_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, local_path\u001b[38;5;241m=\u001b[39mlocal_path\n\u001b[0;32m    218\u001b[0m         )\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# if the directory is already locked, then wait but do not do anything.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m TempFileLock(local_path, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\johan\\anaconda3\\envs\\dl\\Lib\\site-packages\\ray\\train\\_internal\\storage.py:184\u001b[0m, in \u001b[0;36m_download_from_fs_path\u001b[1;34m(fs, fs_path, local_path, filelock)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists_before:\n\u001b[0;32m    183\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(local_path, ignore_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\johan\\anaconda3\\envs\\dl\\Lib\\site-packages\\ray\\train\\_internal\\storage.py:177\u001b[0m, in \u001b[0;36m_download_from_fs_path\u001b[1;34m(fs, fs_path, local_path, filelock)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filelock:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m TempFileLock(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(local_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.lock\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 177\u001b[0m         _pyarrow_fs_copy_files(fs_path, local_path, source_filesystem\u001b[38;5;241m=\u001b[39mfs)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m     _pyarrow_fs_copy_files(fs_path, local_path, source_filesystem\u001b[38;5;241m=\u001b[39mfs)\n",
      "File \u001b[1;32mc:\\Users\\johan\\anaconda3\\envs\\dl\\Lib\\site-packages\\ray\\train\\_internal\\storage.py:110\u001b[0m, in \u001b[0;36m_pyarrow_fs_copy_files\u001b[1;34m(source, destination, source_filesystem, destination_filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Use a large chunk size to speed up large checkpoint transfers.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m64\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mcopy_files(\n\u001b[0;32m    111\u001b[0m     source,\n\u001b[0;32m    112\u001b[0m     destination,\n\u001b[0;32m    113\u001b[0m     source_filesystem\u001b[38;5;241m=\u001b[39msource_filesystem,\n\u001b[0;32m    114\u001b[0m     destination_filesystem\u001b[38;5;241m=\u001b[39mdestination_filesystem,\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    116\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\johan\\anaconda3\\envs\\dl\\Lib\\site-packages\\pyarrow\\fs.py:259\u001b[0m, in \u001b[0;36mcopy_files\u001b[1;34m(source, destination, source_filesystem, destination_filesystem, chunk_size, use_threads)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_info\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m FileType\u001b[38;5;241m.\u001b[39mDirectory:\n\u001b[0;32m    258\u001b[0m     source_sel \u001b[38;5;241m=\u001b[39m FileSelector(source_path, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 259\u001b[0m     _copy_files_selector(source_fs, source_sel,\n\u001b[0;32m    260\u001b[0m                          destination_fs, destination_path,\n\u001b[0;32m    261\u001b[0m                          chunk_size, use_threads)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    263\u001b[0m     _copy_files(source_fs, source_path,\n\u001b[0;32m    264\u001b[0m                 destination_fs, destination_path,\n\u001b[0;32m    265\u001b[0m                 chunk_size, use_threads)\n",
      "File \u001b[1;32mc:\\Users\\johan\\anaconda3\\envs\\dl\\Lib\\site-packages\\pyarrow\\_fs.pyx:1630\u001b[0m, in \u001b[0;36mpyarrow._fs._copy_files_selector\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\johan\\anaconda3\\envs\\dl\\Lib\\site-packages\\pyarrow\\error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 112] Failed copying 'C:/Users/johan/ray_results/train_model_cv_2024-11-26_18-30-35/trial_2b60a_00035_lr=1.0e-04_opt=RMSprop_bs=4/checkpoint_000004/checkpoint.pt' to 'C:/Users/johan/AppData/Local/Temp/checkpoint_tmp_eb1ac5460b9145e2847271a019179487/checkpoint.pt'. Detail: [Windows error 112] Der er ikke tilstrækkelig plads på disken.\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ray import tune\n",
    "from ray.train import Result\n",
    "\n",
    "storage_path = r\"C:\\Users\\johan\\ray_results\"\n",
    "exp_name = \"train_model_cv_2024-11-26_18-30-35\"\n",
    "experiment_path = os.path.join(storage_path, exp_name)\n",
    "print(f\"Loading results from {experiment_path}...\")\n",
    "\n",
    "restored_tuner = tune.Tuner.restore(experiment_path, trainable=train_model_cv)\n",
    "result_grid = restored_tuner.get_results()\n",
    "\n",
    "# Check if there have been errors\n",
    "if result_grid.errors:\n",
    "    print(\"One of the trials failed!\")\n",
    "else:\n",
    "    print(\"No errors!\")\n",
    "    \n",
    "# Get the result with the maximum test set `mean_accuracy`\n",
    "best_result: Result = result_grid.get_best_result()\n",
    "\n",
    "# Load the best checkpoint if it exists\n",
    "if best_result.checkpoint:\n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "else:\n",
    "    raise ValueError(\"No checkpoint found for the best result.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 16:39:38,781\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 40 trial(s):\n",
      "- train_model_cv_83259_00005: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00005: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00005_lr=1.0e-04_opt=Adam_bs=4')\n",
      "- train_model_cv_83259_00022: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00022: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00022_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00017: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00017: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00017_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00033: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00033: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00033_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00015: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00015: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00015_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00010: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00010: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00010_lr=1.0e-04_opt=Adam_bs=4')\n",
      "- train_model_cv_83259_00009: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00009: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00009_lr=1.0e-04_opt=Adam_bs=4')\n",
      "- train_model_cv_83259_00013: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00013: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00013_lr=1.0e-04_opt=Adam_bs=4')\n",
      "- train_model_cv_83259_00023: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00023: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00023_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00029: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00029: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00029_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00030: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00030: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00030_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00040: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00040: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00040_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00044: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00044: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00044_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00034: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00034: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00034_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00020: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00020: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00020_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00025: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00025: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00025_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00028: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00028: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00028_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00032: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00032: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00032_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00039: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00039: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00039_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00031: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00031: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00031_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00035: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00035: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00035_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00036: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00036: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00036_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00012: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00012: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00012_lr=1.0e-04_opt=Adam_bs=4')\n",
      "- train_model_cv_83259_00016: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00016: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00016_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00019: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00019: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00019_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00024: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00024: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00024_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00042: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00042: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00042_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00018: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00018: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00018_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00011: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00011: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00011_lr=1.0e-04_opt=Adam_bs=4')\n",
      "- train_model_cv_83259_00021: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00021: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00021_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00038: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00038: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00038_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00006: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00006: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00006_lr=1.0e-04_opt=Adam_bs=4')\n",
      "- train_model_cv_83259_00014: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00014: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00014_lr=1.0e-04_opt=Adam_bs=4')\n",
      "- train_model_cv_83259_00027: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00027: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00027_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00041: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00041: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00041_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00043: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00043: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00043_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00007: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00007: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00007_lr=1.0e-04_opt=Adam_bs=4')\n",
      "- train_model_cv_83259_00026: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00026: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00026_lr=1.0e-04_opt=SGD_bs=4')\n",
      "- train_model_cv_83259_00037: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00037: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00037_lr=1.0e-04_opt=RMSprop_bs=4')\n",
      "- train_model_cv_83259_00008: FileNotFoundError('Could not fetch metrics for train_model_cv_83259_00008: both result.json and progress.csv were not found at C:/Users/johan/ray_results/train_model_cv_2024-11-26_16-31-22/trial_83259_00008_lr=1.0e-04_opt=Adam_bs=4')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results from C:\\Users\\johan\\ray_results\\train_model_cv_2024-11-26_16-31-22...\n",
      "One of the trials failed!\n",
      "Number of results: 45\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m had an error:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39merror)\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m finished successfully with a loss of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m results_df \u001b[38;5;241m=\u001b[39m result_grid\u001b[38;5;241m.\u001b[39mget_dataframe()\n\u001b[0;32m     30\u001b[0m results_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ray import tune\n",
    "from ray.train import Result\n",
    "\n",
    "storage_path = r\"C:\\Users\\johan\\ray_results\"\n",
    "exp_name = \"train_model_cv_2024-11-26_16-31-22\"\n",
    "experiment_path = os.path.join(storage_path, exp_name)\n",
    "print(f\"Loading results from {experiment_path}...\")\n",
    "\n",
    "restored_tuner = tune.Tuner.restore(experiment_path, trainable=train_model_cv)\n",
    "result_grid = restored_tuner.get_results()\n",
    "\n",
    "# Check if there have been errors\n",
    "if result_grid.errors:\n",
    "    print(\"One of the trials failed!\")\n",
    "else:\n",
    "    print(\"No errors!\")\n",
    "\n",
    "num_results = len(result_grid)\n",
    "print(\"Number of results:\", num_results)\n",
    "\n",
    "# Iterate over results\n",
    "for i, result in enumerate(result_grid):\n",
    "    if result.error:\n",
    "        print(f\"Trial #{i} had an error:\", result.error)\n",
    "        continue\n",
    "\n",
    "    print(f\"Trial #{i} finished successfully with a loss of: {result.metrics['loss']}\")\n",
    "\n",
    "results_df = result_grid.get_dataframe()\n",
    "results_df[[\"training_iteration\", \"loss\"]]\n",
    "\n",
    "print(\"Shortest training time:\", results_df[\"time_total_s\"].min())\n",
    "print(\"Longest training time:\", results_df[\"time_total_s\"].max())\n",
    "\n",
    "ax = None\n",
    "for result in result_grid:\n",
    "    label = f\"lr={result.config['lr']:.4f}, batch_size={result.config['batch_size']}, optimizer={result.config['optimizer']}, fold={result.config['fold']}\"\n",
    "    if ax is None:\n",
    "        ax = result.metrics_dataframe.plot(\"training_iteration\", \"loss\", label=label)\n",
    "    else:\n",
    "        result.metrics_dataframe.plot(\"training_iteration\", \"loss\", ax=ax, label=label)\n",
    "ax.set_title(\"Loss vs. Training Iteration for All Trials\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "\n",
    "# Get the result with the maximum test set `mean_accuracy`\n",
    "best_result: Result = result_grid.get_best_result()\n",
    "\n",
    "print(\"Best trial config: {}\".format(best_result.config))\n",
    "\n",
    "# Get the best trial's final loss and accuracy\n",
    "best_loss = best_result.metrics[\"loss\"]\n",
    "print(\"Best trial final test set loss: {}\".format(best_loss))\n",
    "best_accuracy = best_result.metrics[\"accuracy\"]\n",
    "print(\"Best trial final test set accuracy: {}\".format(best_accuracy))\n",
    "\n",
    "# Load the best model\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "best_trained_model = UnetNoPretraining().to(device)\n",
    "\n",
    "# Load the best checkpoint\n",
    "checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "\n",
    "model_state, optimizer_state = torch.load(checkpoint_path, weights_only=True)\n",
    "best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "best_trained_model.eval()\n",
    "\n",
    "# Load a sample image from the test dataset\n",
    "root_dir = r\"D:\\OneDrive - Aarhus Universitet\\9. Semester\\Deep Learning\\data_gentuity\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=Image.NEAREST),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_dataset = OCTDataset(root_dir, transform=transform, train=False, is_gentuity=True)\n",
    "random_indices = np.random.choice(len(test_dataset), 1, replace=False)\n",
    "sample_image, sample_mask, _, _ = test_dataset[random_indices[0]]  # Change the index to load a different sample\n",
    "\n",
    "# Move the sample image to the appropriate device\n",
    "sample_image = sample_image.to(device).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Make a prediction\n",
    "with torch.no_grad():\n",
    "    prediction = best_trained_model(sample_image)\n",
    "\n",
    "# Convert the prediction to a binary mask\n",
    "predicted_mask = (prediction > 0.5).float()\n",
    "\n",
    "# Plot the sample image, ground truth mask, and predicted mask\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "ax[0].imshow(sample_image.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "ax[0].set_title(\"Sample Image\")\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(sample_mask.squeeze().cpu().numpy(), cmap='gray')\n",
    "ax[1].set_title(\"Ground Truth Mask\")\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(predicted_mask.squeeze().cpu().numpy(), cmap='gray')\n",
    "ax[2].set_title(\"Predicted Mask\")\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
