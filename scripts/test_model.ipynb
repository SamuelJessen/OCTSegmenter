{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from utils.oct_dataset import OCTDataset\n",
    "from utils.lossfunctions import DiceLoss\n",
    "from utils.models import ResNetUNetWithAttention, MedSAM\n",
    "from segment_anything import sam_model_registry\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_with_prediction_and_mask(image, predicted, mask, image_id, save_dir, model_name):\n",
    "    # Convert tensors to numpy arrays\n",
    "    image_np = image.cpu().numpy().transpose(1, 2, 0)\n",
    "    predicted_np = predicted.cpu().numpy().squeeze()\n",
    "    mask_np = mask.cpu().numpy().squeeze()\n",
    "\n",
    "    # Create a figure with 3 subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Plot the original image\n",
    "    axes[0].imshow(image_np)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    # Plot the predicted mask\n",
    "    axes[1].imshow(predicted_np, cmap=\"gray\")\n",
    "    axes[1].set_title(\"Predicted Mask\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    # Plot the ground truth mask\n",
    "    axes[2].imshow(mask_np, cmap=\"gray\")\n",
    "    axes[2].set_title(\"Ground Truth Mask\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    # Save the figure\n",
    "    save_path = os.path.join(save_dir, f\"{image_id}_prediction_{model_name}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_models(models_list, root_dir, save_dir):\n",
    "    # Define device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize lists to store results\n",
    "    model_names = []\n",
    "    dice_coeffs = []\n",
    "    image_ids = []\n",
    "\n",
    "    # Define dataset and transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((1024, 1024), interpolation=Image.NEAREST),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    test_dataset = OCTDataset(\"/Users/studiesamuel/Library/CloudStorage/OneDrive-Aarhusuniversitet/Deep Learning/data_gentuity\",\n",
    "        transform=transform,\n",
    "        train=False,\n",
    "        is_gentuity=True,\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Define loss function\n",
    "    criterion = DiceLoss()\n",
    "\n",
    "    # Loop through models and test each one\n",
    "    for model_name, model_config in models_list:\n",
    "        print(f\"Testing model: {model_name}\")\n",
    "\n",
    "        # Initialize the model\n",
    "        if model_config[\"model\"] == \"Unet\":\n",
    "            net = smp.Unet(\n",
    "                encoder_name=\"resnet50\",\n",
    "                encoder_weights=\"imagenet\",\n",
    "                in_channels=3,\n",
    "                classes=1,\n",
    "            )\n",
    "        elif model_config[\"model\"] == \"DeepLabV3+\":\n",
    "            net = smp.DeepLabV3Plus(\n",
    "                encoder_name=\"resnet50\",\n",
    "                encoder_weights=\"imagenet\",\n",
    "                in_channels=3,\n",
    "                classes=1,\n",
    "            )\n",
    "        elif model_config[\"model\"] == \"MedSam\":\n",
    "            sam_model = sam_model_registry['vit_b'](checkpoint=\"utils/medsam_vit_b.pth\")\n",
    "            net = MedSAM(\n",
    "                image_encoder=sam_model.image_encoder,\n",
    "                mask_decoder=sam_model.mask_decoder,\n",
    "                prompt_encoder=sam_model.prompt_encoder,\n",
    "            )\n",
    "            checkpoint = torch.load(model_config[\"checkpoint_path\"], weights_only=True, map_location=torch.device('cpu'))\n",
    "\n",
    "            # Update the model state with the checkpoint\n",
    "            net.load_state_dict(checkpoint[\"model\"])  # Assuming the checkpoint has a key 'model' for the weights\n",
    "\n",
    "        elif model_config[\"model\"] == \"AttentionUnet\":\n",
    "            net = ResNetUNetWithAttention()\n",
    "\n",
    "        # Load model checkpoint\n",
    "        if(model_config[\"model\"] != \"MedSam\"):\n",
    "            checkpoint_path = model_config[\"checkpoint_path\"]\n",
    "            model_state, optimizer_state = torch.load(checkpoint_path, weights_only=True, map_location=torch.device('cpu'))\n",
    "            net.load_state_dict(model_state)\n",
    "        \n",
    "        net.to(device)\n",
    "        net.eval()\n",
    "\n",
    "        # Test the model\n",
    "        model_dice_scores = []\n",
    "        total_loss = 0  # Accumulate loss for logging\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            for image_id, data in enumerate(test_loader):\n",
    "                if model_config[\"model\"] == \"MedSam\":\n",
    "                    # For MedSAM, process with bounding boxes\n",
    "                    images, masks, _, _ = data\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                    # Get image dimensions\n",
    "                    batch_size, _, height, width = images.size()\n",
    "\n",
    "                    # Create bounding boxes covering the entire image\n",
    "                    bboxes = torch.tensor([[0, 0, width, height]] * batch_size, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "                    # Predict outputs with bounding boxes\n",
    "                    outputs = net(images, bboxes)\n",
    "                    predicted = (outputs > 0.5).float()\n",
    "                else:\n",
    "                    # For other models\n",
    "                    images, masks, _, _ = data\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                    outputs = net(images)\n",
    "                    predicted = (outputs > 0.5).float()\n",
    "\n",
    "                # Calculate loss dice score from torchmetrics\n",
    "                dice_metric = torchmetrics.Dice()\n",
    "                dice_score = dice_metric(predicted, masks.int())\n",
    "                \n",
    "                model_dice_scores.append(dice_score.item())\n",
    "                print(f\"Dice score: {dice_score.item():.4f}\")\n",
    "\n",
    "                # Save image with predictions and ground truth mask\n",
    "                save_image_with_prediction_and_mask(images[0], predicted[0], masks[0], image_id, save_dir, model_name)\n",
    "\n",
    "                # Store image ID for plotting later\n",
    "                image_ids.append(image_id)\n",
    "\n",
    "                print(f\"Progress: {len(model_dice_scores)} / {len(test_loader)}\", end=\"\\r\")\n",
    "\n",
    "                # # if 10 images break\n",
    "                # if len(model_dice_scores) == 5:\n",
    "                #     break\n",
    "\n",
    "\n",
    "\n",
    "        # Store results\n",
    "        model_names.extend([model_name] * len(model_dice_scores))\n",
    "        dice_coeffs.extend(model_dice_scores)\n",
    "\n",
    "        print(f\"{model_name} - Average Dice accuracy: {sum(model_dice_scores) / len(model_dice_scores):.4f}\")\n",
    "    \n",
    "    return model_names, dice_coeffs\n",
    "\n",
    "models_list = [\n",
    "    (\"MedSAM\", {\"model\": \"MedSam\", \"checkpoint_path\": \"models_local/checkpoint_bs=6_medsam_frozen_DiceBCELoss.pth\"}),\n",
    "    (\"AttentionUnet\", {\"model\": \"AttentionUnet\", \"checkpoint_path\": \"models_local/checkpoint_bs=6_AttentionUnetUnFrozen_DICEBCELoss.pt\"}),\n",
    "    (\"U-Net\", {\"model\": \"Unet\", \"checkpoint_path\": \"models_local/checkpoint_bs=6_Unet_unfrozen_DiceBCELoss.pt\"}),\n",
    "    (\"DeepLabV3+\", {\"model\": \"DeepLabV3+\", \"checkpoint_path\": \"models_local/checkpoint_bs=6_Deeplabv3_unfrozen_DiceBCELoss.pt\"}),\n",
    "    \n",
    "]\n",
    "\n",
    "root_dir = \"\"\n",
    "save_dir = \"output_images\"  # Directory to save images with predictions\n",
    "os.makedirs(save_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to get Dice scores and model names\n",
    "model_names, dice_coeffs = test_models(models_list, root_dir, save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataFrame for visualization\n",
    "results_df = pd.DataFrame({\n",
    "    \"Model\": model_names,\n",
    "    \"Dice Score\": dice_coeffs,\n",
    "})\n",
    "\n",
    "# Generate a boxplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x=\"Model\", y=\"Dice Score\", data=results_df, hue=\"Model\", legend=False)\n",
    "plt.title(\"Performance comparison on terumo testset\")\n",
    "plt.ylabel(\"Dice Similarity Coefficient\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show saved image with predictions\n",
    "# Open the image\n",
    "image_path = \"output_images/0_prediction_MedSAM.png\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Display inline in the notebook\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()  # Display the image inline\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearningenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
